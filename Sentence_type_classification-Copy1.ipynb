{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuqiongzhao/assignment2/.env/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "np.random.seed(1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('my_data/myTrainDataset.csv')\n",
    "X_test, Y_test = read_csv('my_data/myTestDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C=3)\n",
    "# Y_oh_test = convert_to_one_hot(Y_train, C=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read glove embedding\n"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word, word_to_embedding_map = read_glove_embedding('my_data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.977195264457002"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(word_to_embedding_map['did'], word_to_embedding_map['was'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    X -- array of sentences, of shape (N, 1)\n",
    "    word_to_index -- a dictionary mapping word to index\n",
    "    max_len -- maximumm number of words in a sentence\n",
    "    \n",
    "    returns:\n",
    "    X_indices -- array of indices of the words in the sentence of shape (N, max_len)\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    X_indices = np.zeros((N, max_len))\n",
    "    \n",
    "    for i in range(N):\n",
    "        words = X[i].lower().split()\n",
    "        j=0\n",
    "        for w in words:\n",
    "            X_indices[i,j] = word_to_index[w]\n",
    "            j = j+1\n",
    "   \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glove_embedding_layer(word_to_embedding_map, word_to_index):\n",
    "    vocab_corpus_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_embedding_map['bus'].shape[0]\n",
    "    emb_matrix = np.zeros((vocab_corpus_len, emb_dim))\n",
    "    \n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index] = word_to_embedding_map[word]\n",
    "    \n",
    "    embedding_layer = Embedding(vocab_corpus_len, emb_dim, trainable=True)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][3] = -0.3403\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = glove_embedding_layer(word_to_embedding_map, word_to_index)\n",
    "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Sentence_type_classification(input_shape, word_to_embedding_map, word_to_index):\n",
    "    sentence_indices = Input(input_shape, dtype = 'int32')\n",
    "    embedding_layer = glove_embedding_layer(word_to_embedding_map,word_to_index)\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    X = Dropout(0.5)(X)\n",
    "    #X = LSTM(128, return_sequences=True)(X)\n",
    "    #X = Dropout(0.5)(X)\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(3)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(sentence_indices, X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 13, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 13, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,669\n",
      "Trainable params: 20,223,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sentence_type_classification((maxLen,), word_to_embedding_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "223/223 [==============================] - 4s 20ms/step - loss: 1.1000 - acc: 0.3274\n",
      "Epoch 2/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 1.0790 - acc: 0.3857\n",
      "Epoch 3/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 1.0696 - acc: 0.4484\n",
      "Epoch 4/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 1.0396 - acc: 0.4484\n",
      "Epoch 5/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.9917 - acc: 0.4843\n",
      "Epoch 6/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.9026 - acc: 0.5874\n",
      "Epoch 7/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.7944 - acc: 0.6368\n",
      "Epoch 8/60\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.7122 - acc: 0.7040\n",
      "Epoch 9/60\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.6618 - acc: 0.7175\n",
      "Epoch 10/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.6532 - acc: 0.6771\n",
      "Epoch 11/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.5185 - acc: 0.7892\n",
      "Epoch 12/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.4268 - acc: 0.8610\n",
      "Epoch 13/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.3556 - acc: 0.8430\n",
      "Epoch 14/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.3035 - acc: 0.8700\n",
      "Epoch 15/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.3338 - acc: 0.8969\n",
      "Epoch 16/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.2545 - acc: 0.9103\n",
      "Epoch 17/60\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.2100 - acc: 0.9193\n",
      "Epoch 18/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.1757 - acc: 0.9283\n",
      "Epoch 19/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.1929 - acc: 0.9327\n",
      "Epoch 20/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0786 - acc: 0.9776\n",
      "Epoch 21/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.1499 - acc: 0.9283\n",
      "Epoch 22/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0640 - acc: 0.9776\n",
      "Epoch 23/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0785 - acc: 0.9686\n",
      "Epoch 24/60\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0462 - acc: 0.9821\n",
      "Epoch 25/60\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0258 - acc: 0.9955\n",
      "Epoch 26/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0236 - acc: 0.9955\n",
      "Epoch 27/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0236 - acc: 0.9865\n",
      "Epoch 28/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0287 - acc: 0.9865\n",
      "Epoch 29/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0371 - acc: 0.9865\n",
      "Epoch 30/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0710 - acc: 0.9686\n",
      "Epoch 31/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.1549 - acc: 0.9327\n",
      "Epoch 32/60\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.2796 - acc: 0.9327\n",
      "Epoch 33/60\n",
      "223/223 [==============================] - 3s 14ms/step - loss: 0.1422 - acc: 0.9372\n",
      "Epoch 34/60\n",
      "223/223 [==============================] - 3s 13ms/step - loss: 0.0692 - acc: 0.9821\n",
      "Epoch 35/60\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0641 - acc: 0.9776\n",
      "Epoch 36/60\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0384 - acc: 0.9865\n",
      "Epoch 37/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0259 - acc: 0.9955\n",
      "Epoch 38/60\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0163 - acc: 0.9955\n",
      "Epoch 39/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 40/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 41/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 43/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0171 - acc: 0.9955\n",
      "Epoch 49/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0273 - acc: 0.9910\n",
      "Epoch 50/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0129 - acc: 0.9955\n",
      "Epoch 51/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0126 - acc: 0.9910\n",
      "Epoch 54/60\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0096 - acc: 0.9955\n",
      "Epoch 56/60\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0109 - acc: 0.9955\n",
      "Epoch 58/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0068 - acc: 0.9955\n",
      "Epoch 59/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0073 - acc: 0.9955\n",
      "Epoch 60/60\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0023 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ff06d68>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs=60, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 8ms/step\n",
      "\n",
      "Test accuracy =  0.8666666746139526\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 3)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected : 1  prediction:  Water the plant once a week 0\n",
      "Expected : 0  prediction:  To do or not to do is a question 2\n",
      "Expected : 1  prediction:  Run for your life 2\n",
      "Expected : 0  prediction:  Tomorrow is my birthday 2\n"
     ]
    }
   ],
   "source": [
    "# This code allows you to see the mislabelled examples\n",
    "C = 3\n",
    "\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('Expected :', Y_test[i], ' prediction: ', X_test[i],  num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can read the book 1\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['You can read the book'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0], np.argmax(model.predict(X_test_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131584"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*(128*128+128*129)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
